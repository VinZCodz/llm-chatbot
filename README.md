# My ChatBot End-to-End application.

**Building an LLM chat application with:**


1. Frontend: Using vanilla JS, HTML and Tailwind CSS
2. Backend: Node.js runtime, with Express server.
3. LLM: Conversational Model, grounded with internet tolling, Tavily.

LLM output are fine tuned with clear and concise few-shot prompts kept separate in a prompt file.

------------
### End Result:
<img width="1390" height="1373" alt="Capture" src="https://github.com/user-attachments/assets/ae65c6d2-eda6-42a1-be40-ff2abe9c1ef7" />
